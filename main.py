""" we import the github.py and use it to load & store it in vector store database"""

# connecting to a vector store database(RAG)

from dotenv import load_dotenv
import os

# https://python.langchain.com/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html#langchain_google_genai.chat_models.ChatGoogleGenerativeAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_astradb import AstraDBVectorStore
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.tools.retriever import create_retriever_tool
from langchain import hub
from github import fetch_github_issues, load_issues

load_dotenv()


def connect_to_vector_store():
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/text-embedding-004", google_api_key=os.getenv("GOOGLE_API_KEY")
    )
    # embedding is a way of actually kind of turning a piece of data in our case textual data into a vector
    # vector is something that exists in multi-dimensional space & this is what we're storing in our vector db
    # so these embedding will be used by the vectore store databse to take our textual data / documents - convert them into vectors 7 then we store them inside the database
    ASTRA_DB_API_ENDPOINT = os.getenv("ASTRA_DB_API_ENDPOINT")
    ASTRA_DB_APPLICATION_TOKEN = os.getenv("ASTRA_DB_APPLICATION_TOKEN")
    desired_namespace = os.getenv("ASTRA_DB_KEYSPACE")

    if desired_namespace:
        ASTRA_DB_KEYSPACE = desired_namespace
    else:
        ASTRA_DB_KEYSPACE = None

    # function to connect to vector store
    vector_store = AstraDBVectorStore(
        embedding=embeddings,
        collection_name="github_issues",  # looks if this collection exists if not creates one
        api_endpoint=ASTRA_DB_API_ENDPOINT,
        token=ASTRA_DB_APPLICATION_TOKEN,
        namespace=ASTRA_DB_KEYSPACE,
    )
    return vector_store


vstore = connect_to_vector_store()

# ADDING DOcuments to vector store database

# ask the users if they want to update the issues
# the reason we ask them because we don't always need to update the issues in the vector store
# it's only may be every day or every week or every month or every year

add_to_vector_store = input("Do you want to update the issues? (y/N): ").lower() in [
    "yes",
    "y",
]
# yes means update the vector store

if add_to_vector_store:
    owner = "techwithtim"
    repo = "Flask-Web-App-Tutorial"
    issues = fetch_github_issues(
        owner, repo
    )  # returns documents generated by langchain which we can add to our vector store

    try:
        vstore.delete_collection()
    except:
        pass

    vstore = connect_to_vector_store()
    vstore.add_documents(issues)

    # results = vstore.similarity_search("flash messages", k=3)
    # for res in results:
    #     print(f"*{res.page_content} {res.metadata}")
    #     $ python main.py
    # C:\Users\abhis\Desktop\AIAgents\CustomAIAgent_RAG_LangChain\github\Lib\site-packages\langchain\_api\module_import.py:87: LangChainDeprecationWarning: Importing GuardrailsOutputParser from langchain.output_parsers is deprecated. Please replace the import with the following:
    # from langchain_community.output_parsers.rail_parser import GuardrailsOutputParser
    #   warnings.warn(
    # Do you want to update the issues? (y/N): y
    # *form update {'author': 'dkardhashi', 'comments': 0, 'body': None, 'labels': [], 'created_at': '2024-05-28T18:33:59Z'}
    # *fix error method=sha256 {'author': 'jessicabrm', 'comments': 0, 'body': None, 'labels': [], 'created_at': '2024-07-19T08:40:53Z'}
    # *where is the .cssi want to edit .css
    #  {'author': 'kelopuu', 'comments': 1, 'body': 'i want to edit .css\r\n', 'labels': [], 'created_at': '2023-05-04T15:08:39Z'}

# llm = ChatGoogleGenerativeAI(model="gemini-1.0-pro")
# embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
# embeddings.embed_query("What's our Q1 revenue?")
